{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72c23ebc",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "21809e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow.keras as tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "b1dbf3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "2a75bdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "622de908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ff82d19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "3cedef24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a174b0d",
   "metadata": {},
   "source": [
    "# Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "5c678b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "0709950f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
       "        0.05098039, 0.28627451, 0.        , 0.        , 0.00392157,\n",
       "        0.01568627, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.00392157, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.        , 0.14117647,\n",
       "        0.53333333, 0.49803922, 0.24313725, 0.21176471, 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.01176471, 0.01568627,\n",
       "        0.        , 0.        , 0.01176471],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
       "        0.8       , 0.69019608, 0.5254902 , 0.56470588, 0.48235294,\n",
       "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04705882, 0.03921569, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60784314,\n",
       "        0.9254902 , 0.81176471, 0.69803922, 0.41960784, 0.61176471,\n",
       "        0.63137255, 0.42745098, 0.25098039, 0.09019608, 0.30196078,\n",
       "        0.50980392, 0.28235294, 0.05882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00392157, 0.        , 0.27058824, 0.81176471,\n",
       "        0.8745098 , 0.85490196, 0.84705882, 0.84705882, 0.63921569,\n",
       "        0.49803922, 0.4745098 , 0.47843137, 0.57254902, 0.55294118,\n",
       "        0.34509804, 0.6745098 , 0.25882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.00392157, 0.00392157, 0.        , 0.78431373, 0.90980392,\n",
       "        0.90980392, 0.91372549, 0.89803922, 0.8745098 , 0.8745098 ,\n",
       "        0.84313725, 0.83529412, 0.64313725, 0.49803922, 0.48235294,\n",
       "        0.76862745, 0.89803922, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.71764706, 0.88235294,\n",
       "        0.84705882, 0.8745098 , 0.89411765, 0.92156863, 0.89019608,\n",
       "        0.87843137, 0.87058824, 0.87843137, 0.86666667, 0.8745098 ,\n",
       "        0.96078431, 0.67843137, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.75686275, 0.89411765,\n",
       "        0.85490196, 0.83529412, 0.77647059, 0.70588235, 0.83137255,\n",
       "        0.82352941, 0.82745098, 0.83529412, 0.8745098 , 0.8627451 ,\n",
       "        0.95294118, 0.79215686, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.01176471, 0.        , 0.04705882, 0.85882353, 0.8627451 ,\n",
       "        0.83137255, 0.85490196, 0.75294118, 0.6627451 , 0.89019608,\n",
       "        0.81568627, 0.85490196, 0.87843137, 0.83137255, 0.88627451,\n",
       "        0.77254902, 0.81960784, 0.20392157],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02352941, 0.        , 0.38823529, 0.95686275, 0.87058824,\n",
       "        0.8627451 , 0.85490196, 0.79607843, 0.77647059, 0.86666667,\n",
       "        0.84313725, 0.83529412, 0.87058824, 0.8627451 , 0.96078431,\n",
       "        0.46666667, 0.65490196, 0.21960784],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01568627,\n",
       "        0.        , 0.        , 0.21568627, 0.9254902 , 0.89411765,\n",
       "        0.90196078, 0.89411765, 0.94117647, 0.90980392, 0.83529412,\n",
       "        0.85490196, 0.8745098 , 0.91764706, 0.85098039, 0.85098039,\n",
       "        0.81960784, 0.36078431, 0.        ],\n",
       "       [0.        , 0.        , 0.00392157, 0.01568627, 0.02352941,\n",
       "        0.02745098, 0.00784314, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.92941176, 0.88627451, 0.85098039,\n",
       "        0.8745098 , 0.87058824, 0.85882353, 0.87058824, 0.86666667,\n",
       "        0.84705882, 0.8745098 , 0.89803922, 0.84313725, 0.85490196,\n",
       "        1.        , 0.30196078, 0.        ],\n",
       "       [0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.24313725,\n",
       "        0.56862745, 0.8       , 0.89411765, 0.81176471, 0.83529412,\n",
       "        0.86666667, 0.85490196, 0.81568627, 0.82745098, 0.85490196,\n",
       "        0.87843137, 0.8745098 , 0.85882353, 0.84313725, 0.87843137,\n",
       "        0.95686275, 0.62352941, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
       "        0.17254902, 0.32156863, 0.41960784, 0.74117647, 0.89411765,\n",
       "        0.8627451 , 0.87058824, 0.85098039, 0.88627451, 0.78431373,\n",
       "        0.80392157, 0.82745098, 0.90196078, 0.87843137, 0.91764706,\n",
       "        0.69019608, 0.7372549 , 0.98039216, 0.97254902, 0.91372549,\n",
       "        0.93333333, 0.84313725, 0.        ],\n",
       "       [0.        , 0.22352941, 0.73333333, 0.81568627, 0.87843137,\n",
       "        0.86666667, 0.87843137, 0.81568627, 0.8       , 0.83921569,\n",
       "        0.81568627, 0.81960784, 0.78431373, 0.62352941, 0.96078431,\n",
       "        0.75686275, 0.80784314, 0.8745098 , 1.        , 1.        ,\n",
       "        0.86666667, 0.91764706, 0.86666667, 0.82745098, 0.8627451 ,\n",
       "        0.90980392, 0.96470588, 0.        ],\n",
       "       [0.01176471, 0.79215686, 0.89411765, 0.87843137, 0.86666667,\n",
       "        0.82745098, 0.82745098, 0.83921569, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.8627451 , 0.94117647, 0.31372549, 0.58823529,\n",
       "        1.        , 0.89803922, 0.86666667, 0.7372549 , 0.60392157,\n",
       "        0.74901961, 0.82352941, 0.8       , 0.81960784, 0.87058824,\n",
       "        0.89411765, 0.88235294, 0.        ],\n",
       "       [0.38431373, 0.91372549, 0.77647059, 0.82352941, 0.87058824,\n",
       "        0.89803922, 0.89803922, 0.91764706, 0.97647059, 0.8627451 ,\n",
       "        0.76078431, 0.84313725, 0.85098039, 0.94509804, 0.25490196,\n",
       "        0.28627451, 0.41568627, 0.45882353, 0.65882353, 0.85882353,\n",
       "        0.86666667, 0.84313725, 0.85098039, 0.8745098 , 0.8745098 ,\n",
       "        0.87843137, 0.89803922, 0.11372549],\n",
       "       [0.29411765, 0.8       , 0.83137255, 0.8       , 0.75686275,\n",
       "        0.80392157, 0.82745098, 0.88235294, 0.84705882, 0.7254902 ,\n",
       "        0.77254902, 0.80784314, 0.77647059, 0.83529412, 0.94117647,\n",
       "        0.76470588, 0.89019608, 0.96078431, 0.9372549 , 0.8745098 ,\n",
       "        0.85490196, 0.83137255, 0.81960784, 0.87058824, 0.8627451 ,\n",
       "        0.86666667, 0.90196078, 0.2627451 ],\n",
       "       [0.18823529, 0.79607843, 0.71764706, 0.76078431, 0.83529412,\n",
       "        0.77254902, 0.7254902 , 0.74509804, 0.76078431, 0.75294118,\n",
       "        0.79215686, 0.83921569, 0.85882353, 0.86666667, 0.8627451 ,\n",
       "        0.9254902 , 0.88235294, 0.84705882, 0.78039216, 0.80784314,\n",
       "        0.72941176, 0.70980392, 0.69411765, 0.6745098 , 0.70980392,\n",
       "        0.80392157, 0.80784314, 0.45098039],\n",
       "       [0.        , 0.47843137, 0.85882353, 0.75686275, 0.70196078,\n",
       "        0.67058824, 0.71764706, 0.76862745, 0.8       , 0.82352941,\n",
       "        0.83529412, 0.81176471, 0.82745098, 0.82352941, 0.78431373,\n",
       "        0.76862745, 0.76078431, 0.74901961, 0.76470588, 0.74901961,\n",
       "        0.77647059, 0.75294118, 0.69019608, 0.61176471, 0.65490196,\n",
       "        0.69411765, 0.82352941, 0.36078431],\n",
       "       [0.        , 0.        , 0.29019608, 0.74117647, 0.83137255,\n",
       "        0.74901961, 0.68627451, 0.6745098 , 0.68627451, 0.70980392,\n",
       "        0.7254902 , 0.7372549 , 0.74117647, 0.7372549 , 0.75686275,\n",
       "        0.77647059, 0.8       , 0.81960784, 0.82352941, 0.82352941,\n",
       "        0.82745098, 0.7372549 , 0.7372549 , 0.76078431, 0.75294118,\n",
       "        0.84705882, 0.66666667, 0.        ],\n",
       "       [0.00784314, 0.        , 0.        , 0.        , 0.25882353,\n",
       "        0.78431373, 0.87058824, 0.92941176, 0.9372549 , 0.94901961,\n",
       "        0.96470588, 0.95294118, 0.95686275, 0.86666667, 0.8627451 ,\n",
       "        0.75686275, 0.74901961, 0.70196078, 0.71372549, 0.71372549,\n",
       "        0.70980392, 0.69019608, 0.65098039, 0.65882353, 0.38823529,\n",
       "        0.22745098, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
       "        0.28235294, 0.16078431, 0.1372549 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "919d3b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_19 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 32)                25120     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "fc97bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "a7ea0320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2628 - accuracy: 0.9028\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2538 - accuracy: 0.9063\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2500 - accuracy: 0.9059\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2458 - accuracy: 0.9094\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2414 - accuracy: 0.9095\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2382 - accuracy: 0.9108\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2363 - accuracy: 0.9111\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2331 - accuracy: 0.9123\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2289 - accuracy: 0.9140\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2280 - accuracy: 0.9153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb9a4861f0>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "9e0fa934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.3459 - accuracy: 0.8807\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3144 - accuracy: 0.8876\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2975 - accuracy: 0.8898\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2883 - accuracy: 0.8955\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2771 - accuracy: 0.8975\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2716 - accuracy: 0.8981\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2634 - accuracy: 0.9022\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2561 - accuracy: 0.9037\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2501 - accuracy: 0.9058\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2450 - accuracy: 0.9096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb9a4573a0>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_test, y_test, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210aa918",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "99ff77ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dropout\n",
    "model2 = keras.models.Sequential([\n",
    "                         keras.layers.Flatten(input_shape=[28,28]),\n",
    "                         keras.layers.Dense(units=32, activation='relu'),Dropout(0.25),\n",
    "                         keras.layers.Dense(units=10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "e6dfe728",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "0b13b55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.6885 - accuracy: 0.7610\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5050 - accuracy: 0.8210\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4678 - accuracy: 0.8324\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4491 - accuracy: 0.8392\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4338 - accuracy: 0.8432\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4183 - accuracy: 0.8487\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4147 - accuracy: 0.8508\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4049 - accuracy: 0.8524\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4000 - accuracy: 0.8538\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3971 - accuracy: 0.8547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb9a568520>"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "2f0aef23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.4645 - accuracy: 0.8360\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4527 - accuracy: 0.8370\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4378 - accuracy: 0.8416\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.4268 - accuracy: 0.8442\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4219 - accuracy: 0.8499\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4144 - accuracy: 0.8481\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4082 - accuracy: 0.8507\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3974 - accuracy: 0.8551\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3978 - accuracy: 0.8522\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3850 - accuracy: 0.8587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fbf3ba20a0>"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_test, y_test, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4bd42c",
   "metadata": {},
   "source": [
    "# EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "f6533287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 88s 3ms/step - loss: 0.2984 - accuracy: 0.8917\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 96s 3ms/step - loss: 0.2870 - accuracy: 0.8951\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 83s 3ms/step - loss: 0.2840 - accuracy: 0.8972\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 80s 3ms/step - loss: 0.2836 - accuracy: 0.8961\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 80s 3ms/step - loss: 0.2803 - accuracy: 0.8970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fbf95b47c0>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "callsbacks=[EarlyStopping(monitor=\"val_accuracy\",patience=3)]\n",
    "model.fit(X_train,y_train,epochs=5,batch_size=2,validation_split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0999e591",
   "metadata": {},
   "source": [
    "# implementation by sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "82855cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "1d9e0528",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=200, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "46262410",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                     random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "bcf75ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 20)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "4d34dd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "01fc441d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97618683, 0.02381317]])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "51ad8c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "c271b94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "82415551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "c94d3e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X, y =make_regression (n_samples=100, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                     random_state=1)\n",
    "regr = MLPRegressor(random_state=1, max_iter=300).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "8884c7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf2 = MLPRegressor(random_state=1, max_iter=300).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "55d66f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7855867869703852"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "6281c8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058321179458752814"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03032f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "de236c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "aaa5e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "7148ac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "96e271c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(40,),\n",
    "    max_iter=8,\n",
    "    \n",
    "\n",
    "    alpha=1e-4,\n",
    "    solver=\"sgd\",\n",
    "    verbose=10,\n",
    "    random_state=1,\n",
    "    learning_rate_init=0.2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "2f735c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.44139186\n",
      "Iteration 2, loss = 0.19174891\n",
      "Iteration 3, loss = 0.13983521\n",
      "Iteration 4, loss = 0.11378556\n",
      "Iteration 5, loss = 0.09443967\n",
      "Iteration 6, loss = 0.07846529\n",
      "Iteration 7, loss = 0.06506307\n",
      "Iteration 8, loss = 0.05534985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.986429\n",
      "Test set score: 0.953061\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "13e19041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By using pandas.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "c6f6bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "d60e9c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_hours</th>\n",
       "      <th>student_marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.83</td>\n",
       "      <td>78.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.56</td>\n",
       "      <td>76.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>78.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.67</td>\n",
       "      <td>71.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.67</td>\n",
       "      <td>84.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>7.53</td>\n",
       "      <td>81.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>8.56</td>\n",
       "      <td>84.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>8.94</td>\n",
       "      <td>86.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>6.60</td>\n",
       "      <td>78.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>8.35</td>\n",
       "      <td>83.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     study_hours  student_marks\n",
       "0           6.83          78.50\n",
       "1           6.56          76.74\n",
       "2            NaN          78.68\n",
       "3           5.67          71.82\n",
       "4           8.67          84.19\n",
       "..           ...            ...\n",
       "195         7.53          81.67\n",
       "196         8.56          84.68\n",
       "197         8.94          86.75\n",
       "198         6.60          78.05\n",
       "199         8.35          83.50\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"student_info.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "0a2700c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_hours</th>\n",
       "      <th>student_marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.83</td>\n",
       "      <td>78.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.56</td>\n",
       "      <td>76.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>78.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.67</td>\n",
       "      <td>71.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.67</td>\n",
       "      <td>84.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_hours  student_marks\n",
       "0         6.83          78.50\n",
       "1         6.56          76.74\n",
       "2          NaN          78.68\n",
       "3         5.67          71.82\n",
       "4         8.67          84.19"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "b7660738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_hours</th>\n",
       "      <th>student_marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>195.000000</td>\n",
       "      <td>200.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.995949</td>\n",
       "      <td>77.93375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.253060</td>\n",
       "      <td>4.92570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.010000</td>\n",
       "      <td>68.57000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.775000</td>\n",
       "      <td>73.38500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.120000</td>\n",
       "      <td>77.71000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.085000</td>\n",
       "      <td>82.32000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.990000</td>\n",
       "      <td>86.99000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       study_hours  student_marks\n",
       "count   195.000000      200.00000\n",
       "mean      6.995949       77.93375\n",
       "std       1.253060        4.92570\n",
       "min       5.010000       68.57000\n",
       "25%       5.775000       73.38500\n",
       "50%       7.120000       77.71000\n",
       "75%       8.085000       82.32000\n",
       "max       8.990000       86.99000"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "7a72714c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_hours</th>\n",
       "      <th>student_marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     study_hours  student_marks\n",
       "0          False          False\n",
       "1          False          False\n",
       "2           True          False\n",
       "3          False          False\n",
       "4          False          False\n",
       "..           ...            ...\n",
       "195        False          False\n",
       "196        False          False\n",
       "197        False          False\n",
       "198        False          False\n",
       "199        False          False\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "96813a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   study_hours    195 non-null    float64\n",
      " 1   student_marks  200 non-null    float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 3.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "1cdae315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "study_hours      5\n",
       "student_marks    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data cleaning\n",
    "df.isnull().sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "56fa7a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "study_hours       6.995949\n",
       "student_marks    77.933750\n",
       "dtype: float64"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "4a915912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "study_hours       7.12\n",
       "student_marks    77.71\n",
       "dtype: float64"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "8293ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.fillna(df.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "dafe8e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "study_hours      0\n",
       "student_marks    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "7d7cee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df2.drop(\"student_marks\",axis=\"columns\")\n",
    "y=df2.drop(\"study_hours\",axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "c31ad1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "272d15e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = MLPRegressor(\n",
    "    hidden_layer_sizes=(40,),\n",
    "    max_iter=8,\n",
    "    \n",
    "\n",
    "    alpha=1e-4,\n",
    "    solver=\"sgd\",\n",
    "    verbose=10,\n",
    "    random_state=1,\n",
    "    learning_rate_init=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "0e2720ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2858.30769180\n",
      "Iteration 2, loss = 12697138292.59885979\n",
      "Iteration 3, loss = 10329644987.27863503\n",
      "Iteration 4, loss = 19332454208.33914948\n",
      "Iteration 5, loss = 29335053727.49843216\n",
      "Iteration 6, loss = 40256799925.73127747\n",
      "Iteration 7, loss = 52047321038.78064728\n",
      "Iteration 8, loss = 64400937219.17457581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1607: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(40,), learning_rate_init=0.2, max_iter=8,\n",
       "             random_state=1, solver=&#x27;sgd&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(40,), learning_rate_init=0.2, max_iter=8,\n",
       "             random_state=1, solver=&#x27;sgd&#x27;, verbose=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(40,), learning_rate_init=0.2, max_iter=8,\n",
       "             random_state=1, solver='sgd', verbose=10)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2.fit(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "83aeb827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: -9690834.153057\n",
      "Test set score: -8422160.737941\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set score: %f\" % mlp2.score(x_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp2.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d326a",
   "metadata": {},
   "source": [
    "#  Different optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "beea8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "fcfb48a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as tk\n",
    "mnist = tk.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) =mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "800858fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "77b0ea9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "a16a13fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "c38ed318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "1788859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "                         keras.layers.Flatten(input_shape=[28,28]),\n",
    "                         keras.layers.Dense(units=32, activation='relu'),\n",
    "                         keras.layers.Dense(units=10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "3c3af2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_25 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 32)                25120     \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "e17d31a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adam\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "01b5debf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nadam\n",
    "model2.compile(optimizer=\"Nadam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "94f64c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adadelta \n",
    "model4.compile(optimizer=\"Adadelta\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "fbb36cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 2.0583 - accuracy: 0.5898\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.6869 - accuracy: 0.8185\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4769 - accuracy: 0.8846\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3903 - accuracy: 0.9039\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3443 - accuracy: 0.9135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fbf34b8d90>"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adam\n",
    "model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6117a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adam\n",
    "accuracy: 0.9135\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "ad03461a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 29.9318 - accuracy: 0.1167\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3460 - accuracy: 0.1155\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2738 - accuracy: 0.1292\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.1967 - accuracy: 0.1753\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.0790 - accuracy: 0.2237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb8736b100>"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nadam\n",
    "model2.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6914692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nadam\n",
    "accuracy: 0.2237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "78562c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.5583 - accuracy: 0.0812\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.5271 - accuracy: 0.0864\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.4968 - accuracy: 0.0926\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.4685 - accuracy: 0.0994\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.4423 - accuracy: 0.1073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb8846e3a0>"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adadelta\n",
    "model4.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0509567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adadelta\n",
    "accuracy: 0.1073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "4e5b58cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.models.Sequential([\n",
    "                         keras.layers.Flatten(input_shape=[28,28]),\n",
    "                         keras.layers.Dense(units=32, activation='relu'),\n",
    "                         keras.layers.Dense(units=10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "d9ffb593",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer=\"RMSProp\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "9fde3828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7733 - accuracy: 0.8681\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6562 - accuracy: 0.8927\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6123 - accuracy: 0.9037\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5673 - accuracy: 0.9115\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5362 - accuracy: 0.9151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fbf422cc70>"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train,y_train,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSProp\n",
    "accuracy=0.9151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "45e57d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = keras.models.Sequential([\n",
    "                         keras.layers.Flatten(input_shape=[28,28]),\n",
    "                         keras.layers.Dense(units=32, activation='relu'),\n",
    "                         keras.layers.Dense(units=10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "ab0acccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.compile(optimizer=\"Adagrad\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "0b098d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 6.4037 - accuracy: 0.3324\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 2.1879 - accuracy: 0.3382\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.9832 - accuracy: 0.3726\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.8717 - accuracy: 0.3974\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.7972 - accuracy: 0.4150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb9dbd1070>"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5a8083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adagrad\n",
    "accuracy=0.4150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "69c5b9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "names = ['Adam','Nadam','Adadelta',\"RMSProp\",\"Adagrad\"]\n",
    "values = [ 91.35,22.00,107.00,91.51,41.35]\n",
    "\n",
    "f = plt.figure(figsize=(15,3),num=10)\n",
    "plt.subplot(131)\n",
    "plt.ylim(10,102)\n",
    "plt.bar(names,values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5339cb4",
   "metadata": {},
   "source": [
    "conclusion - As we can see that the best Adam and RMSProp are giving best accuracy for the given dataset.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbd7f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93ac63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec09949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
